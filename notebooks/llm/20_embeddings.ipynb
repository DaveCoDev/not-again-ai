{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Embeddings\n",
    "\n",
    "This notebook covers how you can use the `create_embeddings` function to create embeddings for text.\n",
    "\n",
    "## Embeddings with Ollama\n",
    "\n",
    "First we instantiate the Ollama client, which is identical to the client we use for chat completions, detailed in [02_ollama_intro.ipynb](./02_ollama_intro.ipynb).\n",
    "\n",
    "Then we use the general `create_embeddings` function to create embeddings passing the `EmbeddingRequest`, \"ollama\" as the provider, and client we initialized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.011252048, 0.053802438, -0.011280932, -0.0730897, -0.038289726]\n"
     ]
    }
   ],
   "source": [
    "from not_again_ai.llm.embedding import EmbeddingRequest, create_embeddings\n",
    "from not_again_ai.llm.embedding.providers.ollama_api import ollama_client as ollama_embedding_client\n",
    "\n",
    "ollama_client = ollama_embedding_client()\n",
    "\n",
    "request = EmbeddingRequest(input=\"This is some text that I want to embed!\", model=\"snowflake-arctic-embed2\")\n",
    "response = create_embeddings(request, \"ollama\", ollama_client)\n",
    "print(response.embeddings[0].embedding[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings with OpenAI\n",
    "\n",
    "The OpenAI client is identical to the client we use for chat completions, detailed in [01_openai_chat_completion.ipynb](./01_openai_chat_completion.ipynb).\n",
    "\n",
    "We then use the general `create_embeddings` function to create embeddings passing the `EmbeddingRequest`, \"openai\" as the provider, and client we initialized.\n",
    "\n",
    "Note that OpenAI supports additional parameters, such as `dimensions` which we show here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16265206038951874, 0.11295679211616516, 0.980196475982666]\n"
     ]
    }
   ],
   "source": [
    "from not_again_ai.llm.embedding.providers.openai_api import openai_client as openai_embedding_client\n",
    "\n",
    "openai_client = openai_embedding_client()\n",
    "request = EmbeddingRequest(\n",
    "    input=\"This is some text that I want to embed with OpenAI!\", model=\"text-embedding-3-small\", dimensions=3\n",
    ")\n",
    "response = create_embeddings(request, \"openai\", openai_client)\n",
    "print(response.embeddings[0].embedding[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can batch requests with either provider.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First embedding: [-0.024765074, 0.051080894, 0.021982849, -0.076628484, -0.07709133]\n",
      "Second embedding: [0.02124997, 0.04338046, -0.011488909, -0.03943117, -0.037866518]\n"
     ]
    }
   ],
   "source": [
    "request = EmbeddingRequest(\n",
    "    input=[\"This is some text that I want to embed with OpenAI!\", \"And embed this too!\"],\n",
    "    model=\"snowflake-arctic-embed2\",\n",
    ")\n",
    "\n",
    "responses = create_embeddings(request, \"ollama\", ollama_client)\n",
    "print(f\"First embedding: {responses.embeddings[0].embedding[:5]}\")\n",
    "print(f\"Second embedding: {responses.embeddings[1].embedding[:5]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
