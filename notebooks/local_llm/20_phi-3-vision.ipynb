{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phi-3-Vision\n",
    "On May 21, 2024 Microsoft released phi-3-vision which is a 4.2B parameter multimodal model with language and vision capabilities. \n",
    "A [cookbook](https://github.com/microsoft/Phi-3CookBook) is available alongside the model being openly available on [Hugging Face](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct).\n",
    "\n",
    "As of May, the model is not available on inference tools like llama.cpp or Ollama which would make it easier to use the model for inference. \n",
    "This notebook is an example for how to setup it up using Hugging Face's transformers library. This does mean that the setup will be quite involved and may not work on many systems.\n",
    "\n",
    "\n",
    "## Installation\n",
    "1. Prerequisites:\n",
    "    - Linux\n",
    "    - Python 3.11 or 3.12\n",
    "    - Modern NVIDIA GPU (3000 Series or higher) with >=16GB\n",
    "1. Install PyTorch - [Getting Started](https://pytorch.org/get-started/locally/).\n",
    "    - Usually this is: `pip install torch torchvision torchaudio`\n",
    "1. Install [flash-attn](https://github.com/Dao-AILab/flash-attention?tab=readme-ov-file#installation-and-features)\n",
    "    - `pip install packaging`\n",
    "    - `pip install flash-attn --no-build-isolation` \n",
    "    - May need install these first:\n",
    "        ```bash\n",
    "        pip install setuptools.\n",
    "        pip install wheel\n",
    "        ```\n",
    "1. `pip install accelerate`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from not_again_ai.local_llm.huggingface.chat_completion import chat_completion_image\n",
    "from not_again_ai.local_llm.huggingface.helpers import load_model, load_processor\n",
    "\n",
    "model_id = \"microsoft/Phi-3-vision-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dave1/git-repos/not-again-ai/.venv/lib/python3.11/site-packages/transformers/models/auto/image_processing_auto.py:510: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_id=model_id)\n",
    "processor = load_processor(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dave1/git-repos/not-again-ai/.venv/lib/python3.11/site-packages/PIL/Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The image depicts a diagram illustrating the process flow within a Semantic Kernel. It includes an 'Application' block on the left, a central 'Kernel' block, and a 'Models' block on the right, with various steps and processes connected by arrows indicating the flow of operations.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Your goal is to understand and describe images.\"},\n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"},\n",
    "]\n",
    "\n",
    "sk_diagram = Path.cwd().parent.parent / \"tests\" / \"llm\" / \"sample_images\" / \"SKDiagram.png\"\n",
    "images = [sk_diagram]\n",
    "\n",
    "response = chat_completion_image(\n",
    "    messages=messages,\n",
    "    images=images,\n",
    "    model_processor=(model, processor),\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "response[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Numbers'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Your goal is to understand and describe images in just a few words.\"},\n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"A cat\"},\n",
    "    {\"role\": \"user\", \"content\": \"<|image_2|>\\nWhat is shown in this image?\"},\n",
    "]\n",
    "\n",
    "cat = Path.cwd().parent.parent / \"tests\" / \"llm\" / \"sample_images\" / \"cat.jpg\"\n",
    "numbers = Path.cwd().parent.parent / \"tests\" / \"llm\" / \"sample_images\" / \"numbers.png\"\n",
    "images = [cat, numbers]\n",
    "\n",
    "response = chat_completion_image(\n",
    "    messages=messages,\n",
    "    images=images,\n",
    "    model_processor=(model, processor),\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "response[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion Tokens: 179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The first image features a close-up of a cat's face. The cat appears to have a mix of grey and white fur, and its eyes are a striking green color. The cat's nose is prominent and pinkish, and its whiskers are long and white. The background is blurred, focusing attention on the cat's face.\\n\\nThe second image is a collection of handwritten numbers and symbols. They are scattered across the image and vary in size and orientation. The numbers are 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, and 12. The symbols include a circle, a square, a triangle, and a cross. The numbers and symbols are black and are placed on a white background.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Your goal is to understand and describe images in just a few words.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"<|image_1|><|image_2|>\\nWhat is shown in these images? Describe the first image first. Then describe the second.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "cat = Path.cwd().parent.parent / \"tests\" / \"llm\" / \"sample_images\" / \"cat.jpg\"\n",
    "numbers = Path.cwd().parent.parent / \"tests\" / \"llm\" / \"sample_images\" / \"numbers.png\"\n",
    "images = [cat, numbers]\n",
    "\n",
    "response = chat_completion_image(\n",
    "    messages=messages,\n",
    "    images=images,\n",
    "    model_processor=(model, processor),\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "print(f\"Completion Tokens: {response['completion_tokens']}\")\n",
    "response[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2+2 is equal to 4.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try inference without images\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is 2+2?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "response = chat_completion_image(\n",
    "    messages=messages,\n",
    "    images=None,\n",
    "    model_processor=(model, processor),\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "response[\"message\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
